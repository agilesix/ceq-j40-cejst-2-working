# How to generate the sample data in this folder

The sample data in this folder can be easily generated by debugging the `data_pipeline/etl/sources/census_acs/etl.py` file
and exporting data using the debugger console. Examples of this exporting are below.

## Why in pickle format?

Exporting as a Pickle file keeps all the metadata about the columns including the data types. If we were to export as CSV then we will need
to code the data types in the test fixtures for all the columns for the comparison to be correct.

### Transform tests input files
- `acs_transform_input.pkl` - this file contains downloaded Census data that is used as input.
- `acs_transform_geojson.geojson` - this file contains the Census GeoJSON data that is used as input.
1. Place a breakpoint in `data_pipeline/etl/sources/census_acs/etl.py` in the `transform` method right at the beginning
 and start the debugger running the ETL run command for Census ACS (`etl-run -d census_acs`).
1. Partially export the `self.df` and `self.geo_df` data to files once the debugger pauses at the breakpoint. Use these
 sample commands in the debugger console. 
```python
t_list = ['01073001100', '01073001400', '01073002000', '01073003802', '01073004000']
self.geo_df[self.geo_df['GEOID10'].isin(t_list)].to_file('data_pipeline/tests/sources/census_acs/data/transform/acs_transform_geojson.geojson')
test_df = self.df[self.df['GEOID10_TRACT'].isin(t_list)].copy()
# Setting this one row to N/A allows the imputations code to succeed
test_df.at[4, self.OFFCAMPUS_UNIVERSITY_BELOW_POVERTY_UNDERGRADUATE] = pd.NA
test_df.to_pickle('data_pipeline/tests/sources/census_acs/data/transform/acs_transform_input.pkl')
```